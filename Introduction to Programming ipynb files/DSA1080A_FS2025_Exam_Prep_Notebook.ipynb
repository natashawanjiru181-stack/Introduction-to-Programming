{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSA 1080A/VA — Exam Prep Notebook (FS 2025)\n",
        "\n",
        "**Sections covered:** From **Working With CSV Files** through **Debugging & Code Correction**.\n",
        "This notebook contains content‑intensive practice questions and runnable code for each item.\n",
        "\n",
        "> Tip: Replace file names like `sales.csv` with your actual paths.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- Setup & environment ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 120)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working With CSV Files\n",
        "### 1) Reading data into a DataFrame using CSV — Practice Questions\n",
        "- Q1. Load a local CSV called `sales.csv` into a DataFrame and parse `date` as datetime.- Q2. Read a `;`-delimited file with `ISO-8859-1` encoding; coerce `revenue` to numeric.- Q3. Read a very large CSV in chunks of 50,000 rows and compute total revenue.- Q4. Compute a new `revenue = price * quantity` after reading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>region</th>\n",
              "      <th>product</th>\n",
              "      <th>category</th>\n",
              "      <th>units</th>\n",
              "      <th>unit_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-01-02</td>\n",
              "      <td>Nairobi</td>\n",
              "      <td>Chai</td>\n",
              "      <td>Drinks</td>\n",
              "      <td>120</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-01-05</td>\n",
              "      <td>Mombasa</td>\n",
              "      <td>Coffee</td>\n",
              "      <td>Drinks</td>\n",
              "      <td>80</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-01-09</td>\n",
              "      <td>Nairobi</td>\n",
              "      <td>Bread</td>\n",
              "      <td>Bakery</td>\n",
              "      <td>200</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-02-01</td>\n",
              "      <td>Kisumu</td>\n",
              "      <td>Chai</td>\n",
              "      <td>Drinks</td>\n",
              "      <td>95</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-02-10</td>\n",
              "      <td>Naivasha</td>\n",
              "      <td>Bread</td>\n",
              "      <td>Bakery</td>\n",
              "      <td>180</td>\n",
              "      <td>1.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        date    region product category  units  unit_price\n",
              "0 2025-01-02   Nairobi    Chai   Drinks    120         2.5\n",
              "1 2025-01-05   Mombasa  Coffee   Drinks     80         3.0\n",
              "2 2025-01-09   Nairobi   Bread   Bakery    200         1.2\n",
              "3 2025-02-01    Kisumu    Chai   Drinks     95         2.5\n",
              "4 2025-02-10  Naivasha   Bread   Bakery    180         1.1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Q1: Basic read with date parsing\n",
        "# Replace 'sales.csv' with your actual file path.\n",
        "df = pd.read_csv(r'C:\\Users\\T2Gic\\Downloads\\sales_q1.csv', parse_dates=['date'])\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Missing column provided to 'parse_dates': 'date'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Q2: Custom delimiter + encoding + numeric coercion\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Replace 'sales_semicolon.csv' with your actual file path.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mT2Gic\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDownloads\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msales_q1.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mISO-8859-1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstring\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mrevenue\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(df.get(\u001b[33m'\u001b[39m\u001b[33mrevenue\u001b[39m\u001b[33m'\u001b[39m), errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m).fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     11\u001b[39m df.head()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2Gic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2Gic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2Gic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2Gic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2Gic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:161\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_usecols_names(\n\u001b[32m    156\u001b[39m             usecols,\n\u001b[32m    157\u001b[39m             \u001b[38;5;28mself\u001b[39m.names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    158\u001b[39m         )\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m._set_noconvert_columns()\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\T2Gic\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:243\u001b[39m, in \u001b[36mParserBase._validate_parse_dates_presence\u001b[39m\u001b[34m(self, columns)\u001b[39m\n\u001b[32m    233\u001b[39m missing_cols = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    234\u001b[39m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m    235\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m     )\n\u001b[32m    241\u001b[39m )\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    244\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing column provided to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mparse_dates\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    248\u001b[39m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[32m    250\u001b[39m ]\n",
            "\u001b[31mValueError\u001b[39m: Missing column provided to 'parse_dates': 'date'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Q2: Custom delimiter + encoding + numeric coercion\n",
        "# Replace 'sales_semicolon.csv' with your actual file path.\n",
        "df = pd.read_csv(\n",
        "    r'C:\\Users\\T2Gic\\Downloads\\sales_q1.csv',\n",
        "    sep=';',\n",
        "    encoding='ISO-8859-1',\n",
        "    dtype={'category': 'string'},\n",
        "    parse_dates=['date']\n",
        ")\n",
        "df['revenue'] = pd.to_numeric(df.get('revenue'), errors='coerce').fillna(0)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q3: Chunked reading for large files\n",
        "# Replace 'sales_big.csv' with your actual file path.\n",
        "total_revenue = 0\n",
        "for chunk in pd.read_csv('sales_big.csv', chunksize=50_000):\n",
        "    chunk['revenue'] = pd.to_numeric(chunk['revenue'], errors='coerce').fillna(0)\n",
        "    total_revenue += chunk['revenue'].sum()\n",
        "print(f'Total revenue (chunked): {total_revenue:,.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q4: Compute revenue while reading (vectorized after load)\n",
        "# Replace 'sales_prices.csv' with your actual file path.\n",
        "df = pd.read_csv('sales_prices.csv', parse_dates=['date'])\n",
        "df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0)\n",
        "df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce').fillna(0)\n",
        "df['revenue'] = df['price'] * df['quantity']\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Displaying sample records\n",
        "- Q1. Show the top 5 rows, then the bottom 3.- Q2. Randomly sample 10 rows reproducibly.- Q3. Show 5 rows per category (stratified sampling).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q1: Head & tail\n",
        "print(df.head(5))\n",
        "print(df.tail(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q2: Reproducible random sample\n",
        "print(df.sample(10, random_state=42))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q3: Stratified sample: 5 rows per category (if available)\n",
        "sampled = df.groupby('category', group_keys=False).apply(lambda g: g.head(5))\n",
        "print(sampled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Confirming column names and data types\n",
        "- Q1. List all column names and dtypes; ensure `date` is datetime and `revenue` numeric.- Q2. Fix trailing whitespace in `'revenue '` by renaming to `'revenue'`.- Q3. Convert `category` to categorical dtype; cast `id` to nullable integer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q1: Inspect names & dtypes\n",
        "print(df.columns.tolist())\n",
        "print(df.dtypes)\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q2: Normalize column names; fix specific typo\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "df = df.rename(columns={'revenue ': 'revenue'})\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q3: Cast dtypes appropriately\n",
        "df['category'] = df['category'].astype('category')\n",
        "df['id'] = pd.to_numeric(df['id'], errors='coerce').astype('Int64')\n",
        "df.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Charts & Visualization\n",
        "### 1) Plotting with Matplotlib from DataFrames — Practice Questions\n",
        "- Q1. Create a daily revenue line chart: x = `date`, y = `revenue`.- Q2. Create a grouped bar chart: total revenue per category by month (Jan/Feb/Mar).- Q3. Create a stacked bar chart of monthly revenue by category.- Q4. Create a pie chart of revenue share by category for Q1 only.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Precompute helpful columns\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df['month'] = df['date'].dt.month_name().str[:3]\n",
        "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce').fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q1: Daily revenue line chart\n",
        "daily = df.groupby('date')['revenue'].sum().sort_index()\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(daily.index, daily.values, marker='o', linestyle='-')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Revenue')\n",
        "plt.title('Daily Revenue Trends (Q1)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q2: Grouped bar chart (month × category)\n",
        "pivot_grouped = df.pivot_table(index='month', columns='category', values='revenue', aggfunc='sum')\n",
        "pivot_grouped = pivot_grouped.reindex(['Jan', 'Feb', 'Mar'])\n",
        "ax = pivot_grouped.plot(kind='bar', figsize=(10, 6))\n",
        "ax.set_xlabel('Month'); ax.set_ylabel('Total Revenue'); ax.set_title('Revenue per Category by Month (Jan–Mar)')\n",
        "plt.xticks(rotation=0); plt.legend(title='Category'); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q3: Stacked bar chart (month × category)\n",
        "ax = pivot_grouped.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='tab20')\n",
        "ax.set_xlabel('Month'); ax.set_ylabel('Total Revenue'); ax.set_title('Monthly Revenue by Category (Stacked)')\n",
        "plt.xticks(rotation=0); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q4: Pie chart (Q1 share by category)\n",
        "q1 = df[df['month'].isin(['Jan', 'Feb', 'Mar'])].groupby('category')['revenue'].sum().sort_values(ascending=False)\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(q1.values, labels=q1.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Q1 Revenue Share by Category'); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Labeling axes and adding titles\n",
        "- Q1. Add axis labels & title; rotate x‑ticks for readability.- Q2. Format y‑axis as currency and add a grid.- Q3. Add a legend for multiple series.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q1: Labels + title + rotated ticks\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(daily.index, daily.values, 'o-', label='Total Revenue')\n",
        "plt.xlabel('Date'); plt.ylabel('Revenue (KES)')\n",
        "plt.title('Daily Revenue Trends')\n",
        "plt.xticks(rotation=45); plt.legend(); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q2: Currency formatting + grid\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(daily.index, daily.values, 'o-')\n",
        "ax.set_xlabel('Date'); ax.set_ylabel('Revenue (KES)')\n",
        "ax.set_title('Daily Revenue (Currency Format)')\n",
        "ax.yaxis.set_major_formatter(mtick.StrMethodFormatter('KES {:,.0f}'))\n",
        "ax.grid(True, alpha=0.3)\n",
        "fig.autofmt_xdate()\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q3: Legend with multiple series\n",
        "cats = ['Electronics', 'Grocery']\n",
        "multi = df[df['category'].isin(cats)].groupby(['date','category'])['revenue'].sum().unstack('category').sort_index()\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for c in multi.columns:\n",
        "    ax.plot(multi.index, multi[c], marker='o', label=c)\n",
        "ax.set_xlabel('Date'); ax.set_ylabel('Revenue (KES)')\n",
        "ax.set_title('Daily Revenue by Selected Categories')\n",
        "ax.legend(title='Category'); ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Understanding chart types and when to use each\n",
        "- Q1. Line vs. bar for daily revenue — plot both and compare.- Q2. Grouped vs. stacked bars — Jan–Mar by category.- Q3. Pie vs. bar for category shares — discuss readability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q1: Line vs. bar for daily revenue\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
        "axes[0].plot(daily.index, daily.values, 'o-'); axes[0].set_title('Line: Daily Revenue')\n",
        "axes[1].bar(daily.index, daily.values); axes[1].set_title('Bar: Daily Revenue')\n",
        "for ax in axes: ax.set_xlabel('Date'); ax.set_ylabel('Revenue'); ax.tick_params(axis='x', rotation=45)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q2: Grouped vs. stacked for Jan–Mar by category\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n",
        "pivot_grouped.plot(kind='bar', ax=axes[0]); axes[0].set_title('Grouped Bars (Compare Categories)')\n",
        "pivot_grouped.plot(kind='bar', stacked=True, ax=axes[1]); axes[1].set_title('Stacked Bars (Total per Month)')\n",
        "for ax in axes: ax.set_xlabel('Month'); ax.set_ylabel('Revenue'); ax.tick_params(axis='x', rotation=0)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q3: Pie vs. bar for category shares\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].pie(q1.values, labels=q1.index, autopct='%1.1f%%'); axes[0].set_title('Pie: Q1 Share')\n",
        "axes[1].bar(q1.index, q1.values); axes[1].set_title('Bar: Q1 Share'); axes[1].tick_params(axis='x', rotation=45)\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Debugging & Code Correction (Very Important)\n",
        "### 1) Identifying syntax errors in Pandas, NumPy, and Matplotlib code — Practice & Fixes\n",
        "- Q1. Spot the missing comma in `plt.plot(...)`.- Q2. Find the unmatched parenthesis in `pd.to_numeric(...)`.- Q3. Replace smart quotes with ASCII quotes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Q1: Missing comma — fixed\n",
        "plt.plot(daily.index, daily.values, marker='o', linestyle='-')\n",
        "\n",
        "# Q2: Unmatched parenthesis — fixed\n",
        "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')\n",
        "\n",
        "# Q3: Smart quotes replaced\n",
        "plt.ylabel('Revenue (KES)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Fixing incorrect imports — Practice & Fixes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Correct imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Fixing wrong DataFrame method calls — Practice & Fixes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Correct grouping call\n",
        "df.groupby(['month','category'])['revenue'].sum()\n",
        "\n",
        "# Access column with spaces using bracket notation\n",
        "_ = df['revenue total'].mean() if 'revenue total' in df.columns else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Fixing mismatched parentheses/brackets — Practice & Fixes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Close the plotting call properly\n",
        "plt.plot(daily.index, daily.values, marker='o', linestyle='-')\n",
        "\n",
        "# List & tuple literals correct\n",
        "x = [1, 2, 3]\n",
        "y = (4, 5, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5) Fixing typos in column names — Practice & Fixes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Robust rename if 'Revenue' exists\n",
        "if 'Revenue' in df.columns and 'revenue' not in df.columns:\n",
        "    df = df.rename(columns={'Revenue': 'revenue'})\n",
        "\n",
        "# Normalize columns: lowercase, strip spaces, replace spaces with underscores\n",
        "df.columns = (\n",
        "    pd.Index(df.columns)\n",
        "      .str.strip()\n",
        "      .str.lower()\n",
        "      .str.replace(r\"\\s+\", \"_\", regex=True)\n",
        ")\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6) Fixing errors in chart creation commands — Practice & Fixes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Sort by date before plotting\n",
        "daily = df.groupby('date')['revenue'].sum().sort_index()\n",
        "plt.plot(daily.index, daily.values, 'o-')\n",
        "plt.show()\n",
        "\n",
        "# Top-5 categories only for clarity\n",
        "q1_totals = df[df['month'].isin(['Jan','Feb','Mar'])].groupby('category')['revenue'].sum().sort_values(ascending=False)\n",
        "top5 = q1_totals.head(5).index\n",
        "pivot_top5 = df[df['category'].isin(top5)].pivot_table(index='month', columns='category', values='revenue', aggfunc='sum')\n",
        "pivot_top5 = pivot_top5.reindex(['Jan','Feb','Mar'])\n",
        "pivot_top5.plot(kind='bar'); plt.show()\n",
        "\n",
        "# Dimension mismatch fix example\n",
        "x = [2, 4, 6, 8, 10]\n",
        "y = [2, 3, 5, 7, 6]  # same length as x\n",
        "plt.plot(x, y, 'o-'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7) Understanding error messages and applying corrections — Practice & Fixes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Try/except with detailed traceback and fallback when reading a problematic CSV\n",
        "import traceback\n",
        "try:\n",
        "    df2 = pd.read_csv('possibly_corrupt.csv', parse_dates=['date'])\n",
        "except Exception:\n",
        "    print('Failed to read CSV:', traceback.format_exc())\n",
        "    df2 = pd.read_csv('possibly_corrupt.csv', engine='python', on_bad_lines='warn')\n",
        "    df2['date'] = pd.to_datetime(df2['date'], errors='coerce')\n",
        "\n",
        "# Assert expected schema\n",
        "def assert_schema(df_in, expected):\n",
        "    \"\"\"expected: dict like {'date': 'datetime64[ns]', 'revenue': 'float64'}\"\"\"\n",
        "    actual = df_in.dtypes.astype(str).to_dict()\n",
        "    for col, dtype in expected.items():\n",
        "        if col not in actual:\n",
        "            raise AssertionError(f'Missing column: {col}')\n",
        "        if actual[col] != dtype:\n",
        "            raise AssertionError(f\"Column '{col}' has dtype {actual[col]} but expected {dtype}\")\n",
        "    return True\n",
        "\n",
        "# Example assertion (adjust expected types to your data)\n",
        "# assert_schema(df, {'date': 'datetime64[ns]', 'revenue': 'float64', 'category': 'category'})\n",
        "\n",
        "# Check sorted index and duplicates\n",
        "daily2 = df.groupby('date')['revenue'].sum()\n",
        "if not daily2.index.is_monotonic_increasing:\n",
        "    print('Warning: Dates are not sorted. Sorting now.')\n",
        "    daily2 = daily2.sort_index()\n",
        "if daily2.index.duplicated().any():\n",
        "    print(f'Warning: Duplicate dates found: {daily2.index.duplicated().sum()} duplicates')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Next steps\n",
        "- Replace file names with your actual CSVs.- Run cells top to bottom.- If you want me to tailor this to your exact schema (column names), share a sample of your CSV.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
